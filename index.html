<p><head>
<title>Robbie Gleichman</title>
</head></p>

<h1>Robbie Gleichman</h1>

<h3><a href="https://github.com/rgleichman">My GitHub</a></h3>

<h1>Projects</h1>

<p>Headers link to GitHub projects. This list is not exhaustive, but it does include most of my public GitHub projects.</p>

<h2>Robotics Projects</h2>

<h3>Carbon Robotics iPad drawing app</h3>

<p><a href="http://www.carbon.ai">Carbon Robotics</a> is building a low cost robotic arm for hobbyists and households. I wrote an iPad app in Swift where the user draws a path on the iPad, and then sends the path to the robot to be executed. <a href="https://www.youtube.com/watch?v=Emq8VNhJx2s">Here is a video</a> that shows someone using the app to decorate a cake. I also wrote most of the robot side software for this project including code that receives the path from the robot, interpolates and scales the path, and runs inverse kinematics on each position in the path to find the joint angles for the final arm trajectory.</p>

<h3><a href="https://github.com/acowley/roshask">roshask</a></h3>

<p>roshask is the <a href="http://www.ros.org">ROS</a> Haskell library written by Anthony Cowley. I added support for <a href="http://wiki.ros.org/Services">ROS service</a> clients. This <a href="https://github.com/acowley/roshask/pull/24">pull request</a> has the commits that were merged. If you are curious about the development process, here is a <a href="https://github.com/acowley/roshask/pull/22">code review</a> with feedback from Anthony.</p>

<h3><a href="https://github.com/rgleichman/rapprentice">Learning from Demonstration</a></h3>

<p>One approach to teaching a robot how to perform a task is to directly demonstrate the task to the robot by manually moving it's arms and controlling its gripper. The robot records the actions the human has demonstrated, along with information about the state of the object being manipulated. The robot then uses the recorded demonstration to manipulate objects in novel environments.</p>

<p>A variation of this approach is to record multiple demonstrations, with the object to be manipulated placed in varying initial states. When asked to preform a task, the robot picks one of its many recorded demonstrations. I helped develop a bootstrapping algorithm that enables the robot to learn from its past successes and failures by improving its choice of demonstration.</p>

<p>For a very specific simulated knot tying task, the bootstrapping algorithm improved the robot's success rate from 60% to 98%. I worked directly with Or Weizman, Ankush Gupta, and Dylan Hadfield-Menell on developing bootstrapping. This work built upon work done by John Schulman, Jonathan Ho, and Cameron Lee (<a href="http://rll.berkeley.edu/isrr2013lfd/">videos and pdf of their paper</a>). This work was done in Pieter Abbeel's lab at UC Berkeley, and the lab's current learning from demonstration work can be found <a href="http://lfd.readthedocs.org/en/latest/">here</a>.</p>

<h3>Nerfinator</h3>

<p>Nerfinator is a robotic Nerf sentry built by Sadegh Asefi and myself as our EE 125 (Introduction to Robotics) final project. It uses the Kinect RGBD camera to aim at faces at varying distances. It also can use a laser pointer to correct its aim. Here is a two minute <a href="https://www.youtube.com/watch?v=oau05MdCPMc">video overview</a>, and a YouTube <a href="https://www.youtube.com/watch?v=3zx1phhTI8c&amp;list=PLj1b-zmkThBO8FdYdLjTq-sJV3GInXYMh">playlist</a> with all of the videos.</p>

<h3>Robot Gripper Optical Sensors</h3>

<p>Pieter Abbeel's lab received from an external lab a few optical sensors for the PR2 robot grippers. On one gripper pad is an array of four IR light sensors. On the the other are four matching IR LED's. If the amount of light received by one of the sensors decreases, then it indicates there is something inside the gripper. These could be used to improve grasping or to sense the shape of objects.</p>

<p>For this project I wrote a simple 2D gripper simulator in Haskell using <a href="http://helm-engine.org/">Helm</a> (<a href="https://github.com/rgleichman/sense">GitHub</a>).
I also started working on using these sensors with the PR2 using ROS and roshask (<a href="https://github.com/rgleichman/uwsensor_demos">GitHub</a>). Unfortunately, these experimental sensors broke often and had to be sent back before I could make much progress.</p>

<h2>Haskell Projects</h2>

<h3><a href="https://github.com/acowley/roshask">roshask</a></h3>

<p>See above</p>

<h3><a href="https://github.com/rgleichman/glance">Glance, a visual representation of Haskell</a></h3>

<p>Glance is a visual representation of Haskell. It is designed (at least initially) to be automatically generated from textual Haskell code.</p>

<h3><a href="https://github.com/rgleichman/smock">smock</a></h3>

<p>smock is a function mocking framework I wrote for Haskell. It is experimental and not very practical; however, I did learn about overlapping instances and data families in Haskell.</p>

<h3><a href="https://github.com/rgleichman/skip">Haskell immutable skip list</a></h3>

<p>This is an experimental module I wrote that can be used for quickly searching through a possibly infinite ascending list. When I tested it, the skip list was faster at creating its searchable data structure than <a href="http://hackage.haskell.org/package/containers-0.5.6.3/docs/Data-Set.html">Data.Set in containers</a>. The skip list's data structure also used less memory. However, the skip list was slower at finding elements, so it would only be faster overall if your code does few searches relative to list size.</p>

<h2>Other Projects</h2>

<h3><a href="https://github.com/rgleichman/shoptype">ShopType</a></h3>

<p><a href="http://rgleichman.github.io/shoptype">Play it here</a></p>

<p>ShopType is a typing game that was created in 2011 for UC Berkeley Art 23 AC, a class that involved teaching Chinese speakers in Oakland CA how to use computers. Jeremy Blalock and I were the programmers for this game. I put this on GitHub in 2015; all commits are bug fixes.</p>

<h3><a href="https://github.com/phoebesimon/fixit">Fixit</a></h3>

<p>Fixit was our group's project for UC Berkeley CS 169 (Software Engineering). We (Phoebe Simon, Chris Turney, Frank YÃ¼,  and I) collaborated with a UC Berkeley housing employee to make a new maintenance request website using Ruby on Rails. This project is notable for having very high test coverage.</p>

<h3><a href="https://github.com/rgleichman/heartBeat">Heartbeat</a></h3>

<p>Heartbeat is an Android app I created that measures your heart rate. To use it, you place your phone's microphone directly on your chest, and the app listens for volume peaks. I wrote this while learning Android development.</p>

<h3><a href="https://github.com/rgleichman/reactor">Trontium Reactor</a></h3>

<p>This code animates a color LED ring with an Arduino. A touch sensor switches animations. This project was for a friend's product video. Here is the <a href="https://vimeo.com/88085657">video</a>, including the animations I created.</p>

<p><br></br>
Contact: You may find my email address by cloning any of my GitHub repositories and then running <code>git log</code>.</p>

<p>Note: This site is created with GitHub pages (<a href="https://github.com/rgleichman/rgleichman.github.io">GitHub source</a>).</p>
